{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPMe6mLqcS+isM6AdE6r1E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amiralitalebi/CN6005_2321004/blob/main/Week9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giFIl8fJtt7G",
        "outputId": "76c58aac-2baf-48e2-85f5-7e9fc8c204a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent itemsets (support >= 60%):\n",
            "{'Eggs'}  -> support = 0.80\n",
            "{'Key-chain'}  -> support = 1.00\n",
            "{'Mango'}  -> support = 0.60\n",
            "{'Onion'}  -> support = 0.60\n",
            "{'Yo-yo'}  -> support = 0.60\n",
            "{'Eggs', 'Key-chain'}  -> support = 0.80\n",
            "{'Onion', 'Eggs'}  -> support = 0.60\n",
            "{'Mango', 'Key-chain'}  -> support = 0.60\n",
            "{'Onion', 'Key-chain'}  -> support = 0.60\n",
            "{'Yo-yo', 'Key-chain'}  -> support = 0.60\n",
            "{'Onion', 'Eggs', 'Key-chain'}  -> support = 0.60\n",
            "\n",
            "Strong association rules (conf >= 80%):\n",
            "{'Eggs'} -> {'Key-chain'}  | support = 0.80, confidence = 1.00, lift = 1.00\n",
            "{'Key-chain'} -> {'Eggs'}  | support = 0.80, confidence = 0.80, lift = 1.00\n",
            "{'Onion'} -> {'Eggs'}  | support = 0.60, confidence = 1.00, lift = 1.25\n",
            "{'Mango'} -> {'Key-chain'}  | support = 0.60, confidence = 1.00, lift = 1.00\n",
            "{'Onion'} -> {'Key-chain'}  | support = 0.60, confidence = 1.00, lift = 1.00\n",
            "{'Yo-yo'} -> {'Key-chain'}  | support = 0.60, confidence = 1.00, lift = 1.00\n",
            "{'Onion'} -> {'Eggs', 'Key-chain'}  | support = 0.60, confidence = 1.00, lift = 1.25\n",
            "{'Onion', 'Eggs'} -> {'Key-chain'}  | support = 0.60, confidence = 1.00, lift = 1.00\n",
            "{'Onion', 'Key-chain'} -> {'Eggs'}  | support = 0.60, confidence = 1.00, lift = 1.25\n"
          ]
        }
      ],
      "source": [
        "from itertools import combinations\n",
        "\n",
        "# Transactions from the sheet\n",
        "transactions = [\n",
        "    {\"Mango\", \"Onion\", \"Nintendo\", \"Key-chain\", \"Eggs\", \"Yo-yo\"},           # T1\n",
        "    {\"Doll\", \"Onion\", \"Nintendo\", \"Key-chain\", \"Eggs\", \"Yo-yo\"},            # T2\n",
        "    {\"Mango\", \"Apple\", \"Key-chain\", \"Eggs\"},                                # T3\n",
        "    {\"Mango\", \"Umbrella\", \"Corn\", \"Key-chain\", \"Yo-yo\"},                    # T4\n",
        "    {\"Corn\", \"Onion\", \"Key-chain\", \"Ice-cream\", \"Eggs\"},                    # T5\n",
        "]\n",
        "\n",
        "min_sup = 0.60  # minimum support (fraction)\n",
        "min_conf = 0.80 # minimum confidence (fraction)\n",
        "\n",
        "num_tx = len(transactions)\n",
        "\n",
        "def support(itemset):\n",
        "    \"\"\"Support of an itemset as a fraction.\"\"\"\n",
        "    count = 0\n",
        "    for t in transactions:\n",
        "        if itemset.issubset(t):\n",
        "            count += 1\n",
        "    return count / num_tx\n",
        "\n",
        "# 1. Generate frequent itemsets (naive but simple)\n",
        "items = sorted({item for t in transactions for item in t})\n",
        "\n",
        "frequent_itemsets = {}  # map: frozenset -> support\n",
        "\n",
        "k = 1\n",
        "while True:\n",
        "    candidates = [set(c) for c in combinations(items, k)]\n",
        "    level_frequents = {}\n",
        "    for cand in candidates:\n",
        "        s = support(cand)\n",
        "        if s >= min_sup:\n",
        "            level_frequents[frozenset(cand)] = s\n",
        "    if not level_frequents:\n",
        "        break\n",
        "    frequent_itemsets.update(level_frequents)\n",
        "    k += 1\n",
        "\n",
        "print(\"Frequent itemsets (support >= 60%):\")\n",
        "for itemset, sup_val in frequent_itemsets.items():\n",
        "    print(f\"{set(itemset)}  -> support = {sup_val:.2f}\")\n",
        "\n",
        "# 2. Generate strong association rules\n",
        "print(\"\\nStrong association rules (conf >= 80%):\")\n",
        "\n",
        "def all_nonempty_proper_subsets(itemset):\n",
        "    items = list(itemset)\n",
        "    for r in range(1, len(items)):\n",
        "        for c in combinations(items, r):\n",
        "            yield set(c)\n",
        "\n",
        "for itemset, sup_XY in frequent_itemsets.items():\n",
        "    if len(itemset) < 2:\n",
        "        continue  # need at least 2 items to make a rule\n",
        "    for A in all_nonempty_proper_subsets(itemset):\n",
        "        B = set(itemset) - A\n",
        "        sup_A = frequent_itemsets[frozenset(A)]\n",
        "        sup_B = frequent_itemsets[frozenset(B)] if frozenset(B) in frequent_itemsets else support(B)\n",
        "        conf = sup_XY / sup_A\n",
        "        if conf >= min_conf:\n",
        "            lift = sup_XY / (sup_A * sup_B)\n",
        "            print(f\"{A} -> {B}  | \"\n",
        "                  f\"support = {sup_XY:.2f}, \"\n",
        "                  f\"confidence = {conf:.2f}, \"\n",
        "                  f\"lift = {lift:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This lab helped me understand how the Apriori algorithm works in a practical way. By calculating support and confidence manually, I could clearly see how frequent itemsets and strong rules are formed. Writing a simple Python version also showed me how these calculations can be automated. Overall, the tasks improved my understanding of association rule mining and made the whole process much easier to follow."
      ],
      "metadata": {
        "id": "-55J2-VgvTuS"
      }
    }
  ]
}